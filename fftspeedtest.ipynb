{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT Speedtest comparing Tensorflow, PyTorch, CuPy, PyFFTW and NumPy.\n",
    "\n",
    "I test the performance of taking an inverse 2D fft on the regular 2D fft of arrays of size 512x512, 1024x1024, 2048x2048 and 4096x4096. The data type is set to Complex 64-bit (Equivalent of float32 for complex numbers) for compatability.\n",
    "\n",
    "GPUs are individual NVidia RTX 2080TI with 11GB of ram.\n",
    "\n",
    "The system has 4 of them, each GPU fft implementation runs on its own GPU.\n",
    "\n",
    "CPU is a 28-core Intel Xeon Gold 5120 CPU @ 2.20GHz \n",
    "\n",
    "Test by @thomasaarholt\n",
    "\n",
    "**See bottom for graphs.**\n",
    "\n",
    "**TLDR: PyTorch GPU fastest and is 4.5 times faster than TensorFlow GPU and CuPy, and the PyTorch CPU version outperforms every other CPU implementation by at least 57 times (including PyFFTW).**\n",
    "\n",
    "My best guess on why the PyTorch cpu solution is better is that it possibly better at taking advantage of the multi-core CPU system the code ran on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blas_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "blis_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    language = c\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "blas_opt_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    language = c\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "lapack_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_lapack_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    language = c\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "lapack_opt_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    language = c\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfftw\n",
    "# Print numpy see whether mkl/blas is available\n",
    "np.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.0.0-beta1\n",
      "PyTorch: 1.2.0\n",
      "Numpy: 1.16.4\n",
      "CuPy: 6.4.0\n",
      "pyFFTW: 0.11.1\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "print('PyTorch: {}'.format(torch.__version__))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('CuPy: {}'.format(cp.__version__))\n",
    "print('pyFFTW: {}'.format(pyfftw.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for each package\n",
    "def tf_ifft2_fft2(data):\n",
    "    data2 = tf.signal.fft2d(data)\n",
    "    return tf.signal.ifft2d(data2)\n",
    "\n",
    "def torch_ifft2_fft2(data):\n",
    "    signal_ndim = 2\n",
    "    data2 = torch.fft(data, signal_ndim=signal_ndim)\n",
    "    return torch.ifft(data2, signal_ndim=signal_ndim)\n",
    "\n",
    "def np_ifft2_fft2(data):\n",
    "    data2 = np.fft.fft2(data)\n",
    "    return np.fft.ifft2(data2)\n",
    "\n",
    "def cp_ifft2_fft2(data):\n",
    "    data2 = cp.fft.fft2(data)\n",
    "    return cp.fft.ifft2(data2)\n",
    "\n",
    "def pyfftw_ifft2_fft2(data):\n",
    "    data2 = pyfftw.interfaces.numpy_fft.fft2(data)\n",
    "    return pyfftw.interfaces.numpy_fft.ifft2(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the functions produce the same result\n",
    "# Using some helper functions to turn all data into numpy arrays\n",
    "from pyms.utils import cx_from_numpy, cx_to_numpy\n",
    "data = np.random.random((20,20)).astype('complex64')\n",
    "\n",
    "dtf = tf_ifft2_fft2(data).numpy()\n",
    "dtorch = cx_to_numpy(torch_ifft2_fft2(cx_from_numpy(data)))\n",
    "dcp = cp.asnumpy(cp_ifft2_fft2(cp.array(data)))\n",
    "dnp = np_ifft2_fft2(data)\n",
    "dfftw = pyfftw_ifft2_fft2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not equal to seven decimals\n",
    "np.testing.assert_almost_equal(dtf, dtorch, decimal=6)\n",
    "np.testing.assert_almost_equal(dtf, dcp, decimal=6)\n",
    "np.testing.assert_almost_equal(dtf, dnp, decimal=6)\n",
    "np.testing.assert_almost_equal(dtf, dnp, decimal=6)\n",
    "np.testing.assert_almost_equal(dtf, dfftw, decimal=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [512, 1024, 2048, 4096] # X * X pixel arrays/tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "totaltimes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on device: /job:localhost/replica:0/task:0/device:CPU:0\n",
      "TensorFlow CPU 512x512\n",
      "49.1 ms ± 121 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "TensorFlow CPU 1024x1024\n",
      "229 ms ± 2.31 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "TensorFlow CPU 2048x2048\n",
      "1.29 s ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "TensorFlow CPU 4096x4096\n",
      "5.72 s ± 14.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "name = 'TensorFlow\\nCPU'\n",
    "names.append(name)\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    tensortimes = []\n",
    "    datas = [tf.dtypes.cast(tf.random.normal(shape=(x,x)), dtype = tf.complex128) for x in sizes]\n",
    "    print(f'Working on device: {datas[0].device}')\n",
    "    for x, data in zip(sizes, datas):\n",
    "        print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "        t = %timeit -o tf_ifft2_fft2(data)\n",
    "        tensortimes.append(t)\n",
    "    totaltimes.append(tensortimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow\n",
      "GPU available: True\n",
      "Working on device: /job:localhost/replica:0/task:0/device:GPU:3\n",
      "TensorFlow GPU 512x512\n",
      "1.94 ms ± 63.9 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "TensorFlow GPU 1024x1024\n",
      "2.37 ms ± 124 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "TensorFlow GPU 2048x2048\n",
      "3.22 ms ± 934 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "TensorFlow GPU 4096x4096\n",
      "16.2 ms ± 1.74 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "name = 'TensorFlow\\nGPU'\n",
    "names.append(name)\n",
    "print('{} available: {}'.format(name, tf.test.is_gpu_available()))\n",
    "with tf.device(\"/device:GPU:3\"):\n",
    "    tensortimes = []\n",
    "    datas = [tf.dtypes.cast(tf.random.normal(shape=(x,x)), dtype = tf.complex128) for x in sizes]\n",
    "    print(f'Working on device: {datas[0].device}')\n",
    "    for x, data in zip(sizes, datas):\n",
    "        print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "        t = %timeit -o tf_ifft2_fft2(data)\n",
    "        tensortimes.append(t)\n",
    "    totaltimes.append(tensortimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on device: cpu\n",
      "PyTorch CPU 512x512\n",
      "506 µs ± 19.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "PyTorch CPU 1024x1024\n",
      "1.26 ms ± 102 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "PyTorch CPU 2048x2048\n",
      "14.5 ms ± 497 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "PyTorch CPU 4096x4096\n",
      "61.3 ms ± 4.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "name = 'PyTorch\\nCPU'\n",
    "device_type = 'cpu'\n",
    "device = torch.device(device_type)\n",
    "names.append(name)\n",
    "torchtimes = []\n",
    "datas = [torch.randn((x,x,2), device=device) for x in sizes]\n",
    "print(f'Working on device: {datas[0].device}')\n",
    "for x, data in zip(sizes, datas):\n",
    "    print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "    t = %timeit -o torch_ifft2_fft2(data)\n",
    "    torchtimes.append(t)\n",
    "totaltimes.append(torchtimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch\n",
      "GPU available: True\n",
      "Working on device: cuda:2\n",
      "PyTorch GPU 512x512\n",
      "101 µs ± 5.15 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "PyTorch GPU 1024x1024\n",
      "194 µs ± 98.5 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "PyTorch GPU 2048x2048\n",
      "906 µs ± 102 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "PyTorch GPU 4096x4096\n",
      "3.58 ms ± 2.94 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "name = 'PyTorch\\nGPU'\n",
    "device_type = 'cuda'\n",
    "device = torch.device('cuda:2')\n",
    "names.append(name)\n",
    "print('{} available: {}'.format(name, torch.cuda.is_available()))\n",
    "torchtimes = []\n",
    "datas = [torch.randn(size=(x,x,2), device=device) for x in sizes]\n",
    "print(f'Working on device: {datas[0].device}')\n",
    "for x, data in zip(sizes, datas):\n",
    "    print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "    t = %timeit -o torch_ifft2_fft2(data)\n",
    "    torchtimes.append(t)\n",
    "totaltimes.append(torchtimes)\n",
    "\n",
    "# # Clear pytorch memory\n",
    "# del datas\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy CPU 512x512\n",
      "24.9 ms ± 561 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Numpy CPU 1024x1024\n",
      "150 ms ± 1.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Numpy CPU 2048x2048\n",
      "831 ms ± 13.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Numpy CPU 4096x4096\n",
      "3.49 s ± 38.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "name = 'Numpy\\nCPU'\n",
    "names.append(name)\n",
    "nptimes = []\n",
    "datas = [np.random.normal(size=(x,x)).astype('complex128') for x in sizes]\n",
    "for x, data in zip(sizes, datas):\n",
    "    print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "    t = %timeit -o np_ifft2_fft2(data)\n",
    "    nptimes.append(t)\n",
    "totaltimes.append(nptimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy GPU 512x512\n",
      "2.38 ms ± 84 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "CuPy GPU 1024x1024\n",
      "2.64 ms ± 712 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "CuPy GPU 2048x2048\n",
      "3.56 ms ± 835 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "CuPy GPU 4096x4096\n",
      "17.1 ms ± 1.67 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "name = 'CuPy\\nGPU'\n",
    "names.append(name)\n",
    "cptimes = []\n",
    "device = cp.cuda.Device(1)\n",
    "with device:\n",
    "    datas = [cp.random.normal(size=(x,x)).astype('complex128') for x in sizes]\n",
    "    for x, data in zip(sizes, datas):\n",
    "        print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "        t = %timeit -o cp_ifft2_fft2(data)\n",
    "        cptimes.append(t)\n",
    "    totaltimes.append(cptimes)\n",
    "\n",
    "# # Clear cupy memory\n",
    "# mempool = cp.get_default_memory_pool()\n",
    "# del datas\n",
    "# mempool.free_all_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyFFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyFFTW CPU 512x512\n",
      "24.2 ms ± 153 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "PyFFTW CPU 1024x1024\n",
      "146 ms ± 976 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "PyFFTW CPU 2048x2048\n",
      "829 ms ± 7.56 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "PyFFTW CPU 4096x4096\n",
      "3.91 s ± 55.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "name = 'PyFFTW\\nCPU'\n",
    "names.append(name)\n",
    "tensortimes = []\n",
    "def pyfftw_array(shape):\n",
    "    arr = pyfftw.empty_aligned(shape, dtype='complex128')\n",
    "    arr[:] = np.random.normal(size=shape) + 1j*np.random.normal(size=shape)\n",
    "    return arr\n",
    "datas = [pyfftw_array((x,x)) for x in sizes]\n",
    "for x, data in zip(sizes, datas):\n",
    "    print('{} {}x{}'.format(\" \".join(name.split('\\n')), x, x))\n",
    "    t = %timeit -o pyfftw_ifft2_fft2(data)\n",
    "    tensortimes.append(t)\n",
    "totaltimes.append(tensortimes)\n",
    "\n",
    "# a = pyfftw.empty_aligned((512, 512), dtype='complex128', n=16)\n",
    "# a[:] = np.random.random((512, 512)) + 1j*np.random.random((512, 512))\n",
    "# %%timeit\n",
    "# b = pyfftw.interfaces.numpy_fft.fft(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092813b90b6f487d9799af496a4944d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot as function of shape\n",
    "fig, AX = plt.subplots(ncols=2, nrows=2, constrained_layout=True, figsize=(14,6))\n",
    "fig.canvas.layout.width = \"1400px\"\n",
    "fig.canvas.layout.height = \"600px\"\n",
    "plt.suptitle('iFFT2(FFT2(array)) performance by array size\\nLower is better')\n",
    "\n",
    "for i in range(len(sizes)):\n",
    "    t = np.array([time[i].average for time in totaltimes]) * 1000 # now in ms\n",
    "    err = np.array([time[i].stdev for time in totaltimes]) * 1000\n",
    "    ax = AX.flatten()[i]\n",
    "    ax.set_title(\"{}x{}\".format(sizes[i], sizes[i]))\n",
    "    ax.bar(names, t)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('FFT Time (ms)')\n",
    "plt.savefig('FFT_Speed_by_size.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average times (in ms) for a 4k x 4k array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow CPU\n",
      "5718.92\n",
      "TensorFlow GPU\n",
      "16.23\n",
      "PyTorch CPU\n",
      "61.28\n",
      "PyTorch GPU\n",
      "3.58\n",
      "Numpy CPU\n",
      "3486.36\n",
      "CuPy GPU\n",
      "17.13\n",
      "PyFFTW CPU\n",
      "3907.17\n",
      "\n",
      "4k x 4k iFFT2(FFT2())\n",
      "PyTorch faster than others by a factor of \n",
      "TensorFlow CPU\n",
      "1596.6\n",
      "TensorFlow GPU\n",
      "4.53\n",
      "PyTorch CPU\n",
      "17.11\n",
      "PyTorch GPU\n",
      "1.0\n",
      "Numpy CPU\n",
      "973.32\n",
      "CuPy GPU\n",
      "4.78\n",
      "PyFFTW CPU\n",
      "1090.8\n"
     ]
    }
   ],
   "source": [
    "times_4k = np.array([time[-1].average for time in totaltimes]) * 1000\n",
    "for i in range(len(names)):\n",
    "    print(\" \".join(names[i].split('\\n')))\n",
    "    print(round(times_4k[i], 2))\n",
    "    \n",
    "pytorch_time_4k = times_4k[3] \n",
    "    \n",
    "print()\n",
    "print('4k x 4k iFFT2(FFT2())')\n",
    "print('PyTorch faster than others by a factor of ')\n",
    "times_4k = np.array([time[-1].average for time in totaltimes]) * 1000\n",
    "for i in range(len(names)):\n",
    "    print(\" \".join(names[i].split('\\n')))\n",
    "    print(round(times_4k[i]/pytorch_time_4k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d54af24a784061a4d3585cde7e47f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot as function of software\n",
    "fig, AX = plt.subplots(ncols=2, nrows=4, constrained_layout=True, figsize=(9,12))\n",
    "fig.canvas.layout.width = \"1300px\"\n",
    "fig.canvas.layout.height = \"1000px\"\n",
    "#alltimes = [1000 * time.average for times in totaltimes[:3] for time in times] # Except Numpy\n",
    "cputimes = [1000 * time.average for times in totaltimes[::2] for time in times] # Except Numpy\n",
    "gputimes = [1000 * time.average for times in totaltimes[1::2] for time in times] # Except Numpy\n",
    "\n",
    "gmx, gmn = max(gputimes), min(gputimes)\n",
    "cmx, cmn = max(cputimes), min(cputimes)\n",
    "plt.suptitle('Log-scale iFFT2(FFT2()) Performance for each program, y-axis similar for GPU software\\nSmaller is better')\n",
    "\n",
    "for i in range(len(names)):\n",
    "    t = np.array([time.average for time in totaltimes[i]]) * 1000 # now in ms\n",
    "    ax = AX.flatten()[i]\n",
    "    ax.set_title(names[i])\n",
    "    sizes_title = [\"{}x{}\".format(size, size) for size in sizes]\n",
    "    ax.bar(sizes_title, t)\n",
    "    ax.set_yscale('log')\n",
    "    if i %2:\n",
    "        ax.set_ylim(gmn/10, gmx*10)\n",
    "    else:\n",
    "        ax.set_ylim(cmn/10, cmx*10)\n",
    "    ax.set_ylabel('FFT Time (ms)')\n",
    "    \n",
    "AX.flatten()[-1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41c2ded6a4c49f3af90110c451e8029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, AX = plt.subplots(ncols=2, nrows=4, constrained_layout=True, figsize=(8,7))\n",
    "fig.canvas.layout.width = \"1300px\"\n",
    "fig.canvas.layout.height = \"1000px\"\n",
    "alltimes = [1000 * time.average for times in totaltimes[:3] for time in times] # Except Numpy\n",
    "mx, mn = max(alltimes), min(alltimes)\n",
    "plt.suptitle('Linear iFFT2(FFT2()) Performance for each program\\nSmaller is better')\n",
    "for i in range(len(names)):\n",
    "    t = np.array([time.average for time in totaltimes[i]]) * 1000 # now in ms\n",
    "    ax = AX.flatten()[i]\n",
    "    ax.set_title(names[i])\n",
    "    sizes_title = [\"{}x{}\".format(size, size) for size in sizes]\n",
    "    ax.bar(sizes_title, t)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('FFT Time (ms)')\n",
    "AX.flatten()[-1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
